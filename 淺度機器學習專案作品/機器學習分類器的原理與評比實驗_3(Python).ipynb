{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 淺度機器學習作品三 : 分類器的原理與評比實驗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 學號 : 411072054 <br> 姓名 : 黃暐宸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkgoldenrod>作品目標</font>：<br> \n",
    "\n",
    "\n",
    "用三種分類器分別對資料進行分類學習與測試。其中分類器包括：\n",
    "1. 多元羅吉斯回歸 (Multinomial Logistic Regression)\n",
    "2. 支援向量機 (Support Vector Machine)\n",
    "3. 神經網路 (Neural Network)\n",
    "\n",
    "目標 :\n",
    "\n",
    "1. 比較三種分類器在原始資料和主成分資料上的表現，找出在各種情況下表現最好的分類器和參數。\n",
    "\n",
    "2. 機器學習最基本的概念是使機器能對多變量資料進行分類，在找表現最好的分類器和參數的過程中，初步了解機器學習到底在做甚麼事情。\n",
    "\n",
    "3. 透過對不同大小的資料集進行分類學習與測試，了解資料量對機器學習造成的影響。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分類器介紹\n",
    "1. 多元羅吉斯回歸 (Multinomial Logistic Regression)是一種用於處理多類別問題的監督學習算法。它使用羅吉斯函數來估計一個觀察值屬於某一類別的概率。最後，模型將觀察值分類到概率最高的類別。\n",
    "\n",
    "2. 支援向量機 (Support Vector Machine):是一種二元分類器，其目標是找到一個超平面來最大化兩個類別之間的邊界。對於非線性問題，它可以使用核函數將資料映射到一個更高維度的空間，使得資料在這個空間中是線性可分的。\n",
    "\n",
    "3. 神經網路 (Neural Network)是一種模仿人腦神經元工作方式的模型，由多個層次的節點（或稱為\"神經元\"）組成。每個節點將前一層的輸出進行加權總和，然後通過一個非線性函數（如ReLU或sigmoid）來產生自己的輸出。透過反向傳播和梯度下降等方法來學習權重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (一)準備資料 :來自 Yale Face 38 人的人臉影像共 2410 張，每張大小 192×168。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "程式碼說明:\n",
    "1. 讀取來自 Yale Face 38 人的人臉影像共 2410 張。\n",
    "2. 訓練資料與測試資料必須分開標準化，而非標準化後再分成訓練與測試資料，將測試資料規劃為 25%。\n",
    "3. 對訓練集和測試集進行標準化處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "D = scipy.io.loadmat(\"allFaces.mat\")\n",
    "X = D[\"faces\"].T # 32256 x 2410, each column represents an image\n",
    "y = np.ndarray.flatten(D[\"nfaces\"])\n",
    "\n",
    "# Create labels for each image\n",
    "y = np.repeat(np.arange(n_persons), y)\n",
    "\n",
    "# Split data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train_ = scaler.fit_transform(X_train)\n",
    "X_test_ = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (2410, 32256)\n",
      "Shape of y: (2410,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (二)用logistic regression分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)以標準化後之原始資料的訓練資料學習，並以測試資料測試準確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "程式碼說明:\n",
    "1. opts = dict(tol = 1e-6, max_iter = int(1e6), verbose=1)創建了一個名為 opts 的字典，設定模型參數(tol: 容忍值, max_iter: 最大迭代次數, verbose: 是否顯示訓練過程)。\n",
    "2. 使用LogisticRegression來建立模型。\n",
    "3. 訓練模型，並使用訓練好的模型來預測測試數據。\n",
    "4. 回報測試資料對於訓練完成的分類器的分類準確率，以兩種不同方式呈現，其中 accuracy_score 比對了測試資料的標籤（y_test）與分類預測值（y_pred），而 clf_original.score 直接給出準確率。兩者結果是一樣的。\n",
    "5. 最後選擇模型演算法(lbfgs)，給出完整的報告(classification_report)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "演算法(lbfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def train_LR(solver, X_train, y_train, X_test, y_test):\n",
    "    opts = dict(tol = 1e-6, max_iter = int(1e6), verbose=1) \n",
    "    clf_LR = LogisticRegression(solver = solver, **opts) # 建立模型 \n",
    "    clf_LR.fit(X_train, y_train) # 訓練模型\n",
    "    y_pred = clf_LR.predict(X_test) # 預測測試資料\n",
    "    # 測試資料之準確率回報\n",
    "    print(f\"{accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "    print(f\"{clf_LR.score(X_test, y_test):.2%}\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.52%\n",
      "\n",
      "96.52%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        22\n",
      "           1       1.00      1.00      1.00        18\n",
      "           2       0.88      1.00      0.93        14\n",
      "           3       0.79      1.00      0.88        11\n",
      "           4       1.00      1.00      1.00        16\n",
      "           5       1.00      1.00      1.00        12\n",
      "           6       1.00      1.00      1.00        12\n",
      "           7       1.00      0.95      0.97        20\n",
      "           8       1.00      0.94      0.97        16\n",
      "           9       0.93      1.00      0.97        14\n",
      "          10       1.00      1.00      1.00        14\n",
      "          11       1.00      0.94      0.97        17\n",
      "          12       1.00      0.86      0.92        21\n",
      "          13       1.00      1.00      1.00        16\n",
      "          14       1.00      1.00      1.00        12\n",
      "          15       1.00      1.00      1.00        18\n",
      "          16       1.00      1.00      1.00        12\n",
      "          17       1.00      1.00      1.00        16\n",
      "          18       1.00      1.00      1.00        20\n",
      "          19       1.00      0.79      0.88        19\n",
      "          20       0.94      1.00      0.97        17\n",
      "          21       1.00      0.93      0.96        14\n",
      "          22       1.00      1.00      1.00        11\n",
      "          23       1.00      0.94      0.97        18\n",
      "          24       1.00      0.95      0.98        21\n",
      "          25       1.00      1.00      1.00         9\n",
      "          26       1.00      0.94      0.97        17\n",
      "          27       1.00      1.00      1.00        13\n",
      "          28       0.92      0.92      0.92        13\n",
      "          29       0.93      0.93      0.93        14\n",
      "          30       1.00      1.00      1.00        23\n",
      "          31       0.88      1.00      0.93        14\n",
      "          32       0.95      0.95      0.95        19\n",
      "          33       0.81      0.93      0.87        14\n",
      "          34       0.94      0.89      0.92        19\n",
      "          35       0.74      1.00      0.85        14\n",
      "          36       1.00      1.00      1.00        18\n",
      "          37       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.97       603\n",
      "   macro avg       0.97      0.97      0.97       603\n",
      "weighted avg       0.97      0.97      0.97       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用函數訓練模型\n",
    "train_LR(\"lbfgs\", X_train_, y_train, X_test_, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn分類報告的項目說明:\n",
    "\n",
    "1. Accuracy : 模型預測正確數量所佔整體的比例。\n",
    "2. Precision : 精確率，被預測為 Positive 的資料中，有多少是真的 Positive。\n",
    "3. Recall : 召回率，它是原本是 Positive 的資料，它能夠召回多少，也就是說在原本 Positive 的資料中被預測出多少。\n",
    "4. F1-score : Precision 與 Recall 調和平均數，模型越接近1，模型越好。\n",
    "5. support : 告訴測試資料集中有多少項目屬於每個類別。\n",
    "6. macro avg : 對每個類別的precision、recall、f1-score加起來求平均。\n",
    "7. weighted avg  : 按照support的權重，對每個類別的precision、recall、f1-score加起來求平均。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果說明 :\n",
    "1. 測試資料之準確率大約97%。\n",
    "2. 在加權平均的評估指標中，精確率、召回率和F1分數都為0.9７，這表示考慮到每個類別的樣本數量後，模型的整體性能仍然非常好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類器性能：\n",
    "\n",
    "1. 演算法lbfgs表現最好，測試資料之準確率大約為97%。\n",
    "2. liblinear演算法是一種針對小數據集的優化算法，對於大數據集，它可能會花費較長的時間，跑了440分鐘都還沒跑完；newton-cg演算法需要計算整個海森矩陣（Hessian matrix）的逆矩陣。這在特徵數量非常大時可能會導致問題。因此先不考慮這兩個演算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)以標準化後之原始資料的主成分之訓練資料學習，並以測試資料測試準確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "演算法(lbfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "程式碼說明 :\n",
    "1. 使用 PCA 對訓練數據 X_train_ 進行擬合，並只保留前45個主成分。\n",
    "2. 使用訓練好的 PCA 模型將訓練數據和測試數據轉換到新的低維空間，得到 Z_train 和 Z_test。\n",
    "3. 設定並訓練羅吉斯迴歸模型。\n",
    "4. 使用模型預測測試數據並計算準確率。\n",
    "5. 輸出模型的分類報告。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.54%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        12\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       0.94      0.94      0.94        16\n",
      "           3       0.94      0.94      0.94        16\n",
      "           4       1.00      1.00      1.00        11\n",
      "           5       0.92      0.92      0.92        24\n",
      "           6       0.90      0.90      0.90        20\n",
      "           7       0.76      0.93      0.84        14\n",
      "           8       1.00      1.00      1.00        18\n",
      "           9       1.00      0.80      0.89        20\n",
      "          10       1.00      0.86      0.92        14\n",
      "          11       1.00      0.92      0.96        13\n",
      "          12       1.00      0.88      0.93        16\n",
      "          13       0.94      0.89      0.91        18\n",
      "          14       0.73      0.89      0.80         9\n",
      "          15       0.81      0.93      0.87        14\n",
      "          16       0.86      0.95      0.90        19\n",
      "          17       1.00      1.00      1.00        12\n",
      "          18       0.59      1.00      0.74        13\n",
      "          19       0.94      0.94      0.94        16\n",
      "          20       1.00      0.95      0.97        20\n",
      "          21       0.90      0.75      0.82        12\n",
      "          22       0.93      0.93      0.93        15\n",
      "          23       1.00      0.69      0.82        13\n",
      "          24       1.00      1.00      1.00        20\n",
      "          25       1.00      0.93      0.97        15\n",
      "          26       0.95      0.95      0.95        19\n",
      "          27       0.95      0.78      0.86        23\n",
      "          28       0.95      1.00      0.97        19\n",
      "          29       1.00      0.93      0.97        15\n",
      "          30       0.84      0.94      0.89        17\n",
      "          31       0.80      0.94      0.86        17\n",
      "          32       1.00      0.95      0.97        19\n",
      "          33       0.83      0.67      0.74        15\n",
      "          34       0.86      1.00      0.92        18\n",
      "          35       1.00      0.80      0.89        15\n",
      "          36       0.91      1.00      0.95        10\n",
      "          37       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.92       603\n",
      "   macro avg       0.92      0.92      0.91       603\n",
      "weighted avg       0.93      0.92      0.92       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 45).fit(X_train_)\n",
    "Z_train = pca.transform(X_train_)\n",
    "Z_test = pca.transform(X_test_)\n",
    "opts = dict(tol = 1e-6, max_iter = int(1e6), verbose=1)\n",
    "solver = \"lbfgs\" \n",
    "clf_PCA = LogisticRegression(solver = solver, **opts)\n",
    "clf_PCA.fit(Z_train, y_train)\n",
    "y_pred = clf_PCA.predict(Z_test)\n",
    "print(f\"{clf_PCA.score(Z_test, y_test):.2%}\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果說明 :\n",
    "1. 測試資料之準確率92%。\n",
    "2. 在加權平均的評估指標中，精確率、召回率和F1分數分別為0.93、0.92，、0.92，這表示考慮到每個類別的樣本數量後，模型的整體性表還可以。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "演算法(liblinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]88.23%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.83      0.74        12\n",
      "           1       1.00      0.85      0.92        13\n",
      "           2       0.88      0.94      0.91        16\n",
      "           3       0.75      0.94      0.83        16\n",
      "           4       0.92      1.00      0.96        11\n",
      "           5       0.84      0.88      0.86        24\n",
      "           6       0.73      0.80      0.76        20\n",
      "           7       0.87      0.93      0.90        14\n",
      "           8       1.00      0.94      0.97        18\n",
      "           9       0.93      0.70      0.80        20\n",
      "          10       1.00      0.71      0.83        14\n",
      "          11       1.00      0.77      0.87        13\n",
      "          12       1.00      0.75      0.86        16\n",
      "          13       1.00      0.83      0.91        18\n",
      "          14       0.82      1.00      0.90         9\n",
      "          15       0.78      1.00      0.88        14\n",
      "          16       0.86      0.95      0.90        19\n",
      "          17       0.92      1.00      0.96        12\n",
      "          18       0.73      0.85      0.79        13\n",
      "          19       0.91      0.62      0.74        16\n",
      "          20       1.00      0.90      0.95        20\n",
      "          21       1.00      0.83      0.91        12\n",
      "          22       1.00      0.93      0.97        15\n",
      "          23       0.82      0.69      0.75        13\n",
      "          24       0.95      1.00      0.98        20\n",
      "          25       0.94      1.00      0.97        15\n",
      "          26       1.00      1.00      1.00        19\n",
      "          27       0.95      0.83      0.88        23\n",
      "          28       0.89      0.84      0.86        19\n",
      "          29       0.82      0.93      0.87        15\n",
      "          30       0.89      0.94      0.91        17\n",
      "          31       0.76      0.94      0.84        17\n",
      "          32       0.90      0.95      0.92        19\n",
      "          33       0.75      0.80      0.77        15\n",
      "          34       0.89      0.94      0.92        18\n",
      "          35       0.92      0.80      0.86        15\n",
      "          36       0.71      1.00      0.83        10\n",
      "          37       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           0.88       603\n",
      "   macro avg       0.89      0.88      0.88       603\n",
      "weighted avg       0.89      0.88      0.88       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 45).fit(X_train_)\n",
    "Z_train = pca.transform(X_train_)\n",
    "Z_test = pca.transform(X_test_)\n",
    "opts = dict(tol = 1e-6, max_iter = int(1e6), verbose=1)\n",
    "solver = \"liblinear\"\n",
    "clf_PCA = LogisticRegression(solver = solver, **opts)\n",
    "clf_PCA.fit(Z_train, y_train)\n",
    "y_pred = clf_PCA.predict(Z_test)\n",
    "print(f\"{clf_PCA.score(Z_test, y_test):.2%}\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果說明 :\n",
    "1. 測試資料之準確率88%。\n",
    "2. 在加權平均的評估指標中，精確率、召回率和F1分數都為88，這表示考慮到每個類別的樣本數量後，模型的整體性表還可以。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "演算法(newton-cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.21%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        12\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       0.94      0.94      0.94        16\n",
      "           3       0.94      0.94      0.94        16\n",
      "           4       1.00      1.00      1.00        11\n",
      "           5       0.95      0.88      0.91        24\n",
      "           6       0.90      0.90      0.90        20\n",
      "           7       0.82      1.00      0.90        14\n",
      "           8       1.00      1.00      1.00        18\n",
      "           9       1.00      0.80      0.89        20\n",
      "          10       1.00      0.86      0.92        14\n",
      "          11       1.00      1.00      1.00        13\n",
      "          12       1.00      0.88      0.93        16\n",
      "          13       0.94      0.89      0.91        18\n",
      "          14       0.73      0.89      0.80         9\n",
      "          15       0.81      0.93      0.87        14\n",
      "          16       0.90      0.95      0.92        19\n",
      "          17       1.00      1.00      1.00        12\n",
      "          18       0.57      1.00      0.72        13\n",
      "          19       0.94      0.94      0.94        16\n",
      "          20       1.00      0.95      0.97        20\n",
      "          21       1.00      0.75      0.86        12\n",
      "          22       0.94      1.00      0.97        15\n",
      "          23       1.00      0.77      0.87        13\n",
      "          24       1.00      1.00      1.00        20\n",
      "          25       1.00      0.93      0.97        15\n",
      "          26       0.95      0.95      0.95        19\n",
      "          27       0.95      0.78      0.86        23\n",
      "          28       0.95      1.00      0.97        19\n",
      "          29       1.00      0.93      0.97        15\n",
      "          30       0.84      0.94      0.89        17\n",
      "          31       0.81      1.00      0.89        17\n",
      "          32       1.00      0.95      0.97        19\n",
      "          33       0.83      0.67      0.74        15\n",
      "          34       0.90      1.00      0.95        18\n",
      "          35       1.00      0.80      0.89        15\n",
      "          36       0.91      1.00      0.95        10\n",
      "          37       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.92       603\n",
      "   macro avg       0.93      0.92      0.92       603\n",
      "weighted avg       0.93      0.92      0.92       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 45).fit(X_train_)\n",
    "Z_train = pca.transform(X_train_)\n",
    "Z_test = pca.transform(X_test_)\n",
    "opts = dict(tol = 1e-6, max_iter = int(1e6), verbose=1)\n",
    "solver = \"newton-cg\"\n",
    "clf_PCA = LogisticRegression(solver = solver, **opts)\n",
    "clf_PCA.fit(Z_train, y_train)\n",
    "y_pred = clf_PCA.predict(Z_test)\n",
    "print(f\"{clf_PCA.score(Z_test, y_test):.2%}\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果說明 :\n",
    "1. 測試資料之準確率92%。\n",
    "2. 在加權平均的評估指標中，精確率、召回率和F1分數分別為0.93、0.92、0.92，這表示考慮到每個類別的樣本數量後，模型的整體性表還可以。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類器性能：\n",
    "\n",
    "演算法lbfgs和newton-cg在只保留前45個主成分的表現最好，測試資料之準確率大約為92%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (三)SVM 分群"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)以標準化後之原始資料的訓練資料學習，並以測試資料測試準確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "程式碼說明：\n",
    "1. 函數定義：train_and_evaluate函數接收一個分類器（clf）和訓練集與測試集的數據。這個函數的目的是訓練分類器並評估其在測試集上的性能。\n",
    "2. 訓練模型，其中X_train和y_train分別是訓練數據的特徵和標籤。\n",
    "3. 對測試數據進行預測，並將預測結果存儲在predictions變量中。\n",
    "4. 使用SVC(kernel=\"＊＊＊\", **opts)來建立SVM分類器並選定演算法，最後產出結果報告。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    # Fit the classifier with the data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels of the test data\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    # Calculate and print the accuracy score\n",
    "    acc_score = accuracy_score(y_test, predictions)\n",
    "    print(f\"Accuracy Score: {acc_score:.2%}\")\n",
    "\n",
    "    # Print the classification report\n",
    "    print(classification_report(y_test, predictions, zero_division=0))\n",
    "    \n",
    "# Define the SVM classifier\n",
    "C = 1 # SVM regularization parameter\n",
    "opts = dict(C = C, tol = 1e-6, max_iter = int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 90.71%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        12\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       0.84      1.00      0.91        16\n",
      "           3       0.84      1.00      0.91        16\n",
      "           4       0.85      1.00      0.92        11\n",
      "           5       0.89      1.00      0.94        24\n",
      "           6       0.95      0.95      0.95        20\n",
      "           7       0.52      0.93      0.67        14\n",
      "           8       0.94      0.89      0.91        18\n",
      "           9       0.74      0.70      0.72        20\n",
      "          10       1.00      0.93      0.96        14\n",
      "          11       1.00      0.92      0.96        13\n",
      "          12       1.00      0.88      0.93        16\n",
      "          13       1.00      0.89      0.94        18\n",
      "          14       0.89      0.89      0.89         9\n",
      "          15       0.88      1.00      0.93        14\n",
      "          16       1.00      1.00      1.00        19\n",
      "          17       0.92      1.00      0.96        12\n",
      "          18       0.68      1.00      0.81        13\n",
      "          19       0.83      0.94      0.88        16\n",
      "          20       1.00      0.95      0.97        20\n",
      "          21       1.00      0.92      0.96        12\n",
      "          22       1.00      0.93      0.97        15\n",
      "          23       0.93      1.00      0.96        13\n",
      "          24       1.00      0.95      0.97        20\n",
      "          25       1.00      0.93      0.97        15\n",
      "          26       1.00      0.84      0.91        19\n",
      "          27       1.00      0.83      0.90        23\n",
      "          28       0.83      1.00      0.90        19\n",
      "          29       0.78      0.93      0.85        15\n",
      "          30       1.00      0.94      0.97        17\n",
      "          31       0.94      1.00      0.97        17\n",
      "          32       1.00      0.79      0.88        19\n",
      "          33       1.00      0.53      0.70        15\n",
      "          34       0.94      0.89      0.91        18\n",
      "          35       1.00      0.80      0.89        15\n",
      "          36       1.00      0.90      0.95        10\n",
      "          37       1.00      0.62      0.76        13\n",
      "\n",
      "    accuracy                           0.91       603\n",
      "   macro avg       0.92      0.91      0.91       603\n",
      "weighted avg       0.92      0.91      0.91       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVC(kernel=\"linear\", **opts)\n",
    "train_and_evaluate(clf_svm, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果說明 :\n",
    "1. 測試資料之準確率91%。\n",
    "2. 在加權平均的評估指標中，精確率、召回率和F1分數分別為0.92、0.91、0.91，這表示考慮到每個類別的樣本數量後，模型的整體性表還可以。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel(rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 1.66%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        16\n",
      "           3       0.00      0.00      0.00        16\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.00      0.00      0.00        24\n",
      "           6       0.00      0.00      0.00        20\n",
      "           7       0.00      0.00      0.00        14\n",
      "           8       0.00      0.00      0.00        18\n",
      "           9       0.00      0.00      0.00        20\n",
      "          10       0.00      0.00      0.00        14\n",
      "          11       0.00      0.00      0.00        13\n",
      "          12       0.00      0.00      0.00        16\n",
      "          13       0.00      0.00      0.00        18\n",
      "          14       0.00      0.00      0.00         9\n",
      "          15       0.00      0.00      0.00        14\n",
      "          16       0.00      0.00      0.00        19\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        13\n",
      "          19       0.00      0.00      0.00        16\n",
      "          20       0.00      0.00      0.00        20\n",
      "          21       0.00      0.00      0.00        12\n",
      "          22       0.00      0.00      0.00        15\n",
      "          23       0.00      0.00      0.00        13\n",
      "          24       0.00      0.00      0.00        20\n",
      "          25       0.00      0.00      0.00        15\n",
      "          26       0.00      0.00      0.00        19\n",
      "          27       0.00      0.00      0.00        23\n",
      "          28       0.00      0.00      0.00        19\n",
      "          29       0.00      0.00      0.00        15\n",
      "          30       0.00      0.00      0.00        17\n",
      "          31       0.00      0.00      0.00        17\n",
      "          32       0.00      0.00      0.00        19\n",
      "          33       0.00      0.00      0.00        15\n",
      "          34       0.00      0.00      0.00        18\n",
      "          35       0.00      0.00      0.00        15\n",
      "          36       0.02      1.00      0.03        10\n",
      "          37       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.02       603\n",
      "   macro avg       0.00      0.03      0.00       603\n",
      "weighted avg       0.00      0.02      0.00       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVC(kernel=\"rbf\", gamma=0.2, **opts)\n",
    "train_and_evaluate(clf_svm, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果說明 :\n",
    "1. 測試資料之準確率2%。\n",
    "2. 在加權平均的評估指標中，精確率、召回率和F1分數分別為0.00、0.02、0.00，模型的整體性表現非常糟糕。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel(poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 67.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.83      0.54        12\n",
      "           1       1.00      0.23      0.38        13\n",
      "           2       0.65      0.69      0.67        16\n",
      "           3       0.87      0.81      0.84        16\n",
      "           4       0.53      0.91      0.67        11\n",
      "           5       0.63      0.92      0.75        24\n",
      "           6       0.60      0.75      0.67        20\n",
      "           7       0.53      0.71      0.61        14\n",
      "           8       1.00      0.50      0.67        18\n",
      "           9       0.41      0.35      0.38        20\n",
      "          10       0.67      0.86      0.75        14\n",
      "          11       0.85      0.85      0.85        13\n",
      "          12       1.00      0.31      0.48        16\n",
      "          13       0.65      0.83      0.73        18\n",
      "          14       0.57      0.89      0.70         9\n",
      "          15       0.74      1.00      0.85        14\n",
      "          16       0.82      0.95      0.88        19\n",
      "          17       0.31      0.92      0.46        12\n",
      "          18       0.91      0.77      0.83        13\n",
      "          19       0.69      0.56      0.62        16\n",
      "          20       0.72      0.90      0.80        20\n",
      "          21       0.43      0.75      0.55        12\n",
      "          22       0.61      0.93      0.74        15\n",
      "          23       0.75      0.46      0.57        13\n",
      "          24       0.72      0.90      0.80        20\n",
      "          25       0.73      0.73      0.73        15\n",
      "          26       1.00      0.53      0.69        19\n",
      "          27       0.80      0.70      0.74        23\n",
      "          28       0.75      0.79      0.77        19\n",
      "          29       0.58      0.93      0.72        15\n",
      "          30       1.00      0.53      0.69        17\n",
      "          31       0.81      0.76      0.79        17\n",
      "          32       1.00      0.53      0.69        19\n",
      "          33       1.00      0.13      0.24        15\n",
      "          34       1.00      0.17      0.29        18\n",
      "          35       1.00      0.40      0.57        15\n",
      "          36       1.00      0.40      0.57        10\n",
      "          37       0.75      0.23      0.35        13\n",
      "\n",
      "    accuracy                           0.67       603\n",
      "   macro avg       0.75      0.67      0.65       603\n",
      "weighted avg       0.76      0.67      0.65       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVC(kernel=\"poly\", degree=3, gamma=\"auto\", **opts)\n",
    "train_and_evaluate(clf_svm, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果說明 :\n",
    "1. 測試資料之準確率67%。\n",
    "2. 在加權平均的評估指標中，精確率、召回率和F1分數分別為0.76、0.67、0.65，這表示考慮到每個類別的樣本數量後，模型的整體性表現有待加強。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類器性能：\n",
    "\n",
    "kernel(linear)表現最好，測試資料之準確率大約為91%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)以標準化後之原始資料的主成分之訓練資料學習，並以測試資料測試準確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "程式碼說明 :\n",
    "1. 使用 PCA 對訓練數據 X_train_ 進行擬合，並將其降維到兩個主成分。\n",
    "2. 使用訓練好的 PCA 模型將訓練數據和測試數據轉換到新的低維空間，得到 Z_train 和 Z_test。\n",
    "3. 定義SVM分類器。設置SVM的正則化參數C為1，並將其與其他參數一起存儲在opts中。\n",
    "4. 使用PCA轉換後的訓練數據Z_train和對應的標籤y_train來訓練SVM分類器。\n",
    "5. 輸出模型的分類報告。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def train_and_evaluate(clf_svm, X_train_, X_test_, y_train, y_test):\n",
    "    # Apply PCA to the training data and transform it\n",
    "    pca = PCA(n_components = 45).fit(X_train_)\n",
    "    Z_train = pca.transform(X_train_)\n",
    "    Z_test = pca.transform(X_test_)\n",
    "\n",
    "    # Fit the SVM classifier with the PCA transformed data\n",
    "    clf_svm.fit(Z_train, y_train)\n",
    "\n",
    "    # Predict the labels of the PCA transformed test data\n",
    "    predictions = clf_svm.predict(Z_test)\n",
    "\n",
    "    # Calculate and print the accuracy score\n",
    "    acc_score = accuracy_score(y_test, predictions)\n",
    "    print(f\"Accuracy Score: {acc_score:.2%}\")\n",
    "\n",
    "    # Print the classification report\n",
    "    print(classification_report(y_test, predictions, zero_division=0))\n",
    "\n",
    "# Define the SVM classifier\n",
    "C = 1 # SVM regularization parameter\n",
    "opts = dict(C = C, tol = 1e-6, max_iter = int(1e6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 92.87%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        17\n",
      "           1       0.81      0.89      0.85        19\n",
      "           2       0.89      0.89      0.89        19\n",
      "           3       1.00      1.00      1.00        14\n",
      "           4       0.88      0.82      0.85        17\n",
      "           5       0.80      1.00      0.89        12\n",
      "           6       0.91      1.00      0.95        21\n",
      "           7       0.93      0.93      0.93        15\n",
      "           8       1.00      0.89      0.94        18\n",
      "           9       0.67      0.89      0.76        18\n",
      "          10       1.00      1.00      1.00        12\n",
      "          11       1.00      1.00      1.00        17\n",
      "          12       0.94      0.83      0.88        18\n",
      "          13       1.00      1.00      1.00        12\n",
      "          14       0.94      0.94      0.94        17\n",
      "          15       1.00      0.85      0.92        13\n",
      "          16       1.00      1.00      1.00        18\n",
      "          17       1.00      1.00      1.00        15\n",
      "          18       0.94      1.00      0.97        17\n",
      "          19       0.90      1.00      0.95         9\n",
      "          20       0.71      1.00      0.83        10\n",
      "          21       1.00      1.00      1.00        16\n",
      "          22       1.00      1.00      1.00        13\n",
      "          23       0.94      0.84      0.89        19\n",
      "          24       0.86      1.00      0.92        12\n",
      "          25       0.92      0.92      0.92        13\n",
      "          26       0.94      1.00      0.97        15\n",
      "          27       1.00      0.95      0.97        19\n",
      "          28       0.94      0.84      0.89        19\n",
      "          29       0.83      1.00      0.90        19\n",
      "          30       0.86      1.00      0.92        12\n",
      "          31       0.96      1.00      0.98        23\n",
      "          32       1.00      1.00      1.00        11\n",
      "          33       1.00      0.80      0.89        15\n",
      "          34       1.00      0.80      0.89        20\n",
      "          35       1.00      0.79      0.88        14\n",
      "          36       1.00      0.67      0.80        15\n",
      "          37       1.00      0.90      0.95        20\n",
      "\n",
      "    accuracy                           0.93       603\n",
      "   macro avg       0.94      0.93      0.93       603\n",
      "weighted avg       0.94      0.93      0.93       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVC(kernel=\"linear\", **opts)\n",
    "train_and_evaluate(clf_svm, X_train_, X_test_, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果說明 :\n",
    "1. 測試資料之準確率93%。\n",
    "2. 在加權平均的評估指標中，精確率、召回率和F1分數分別為0.94、0.93、0.93，這表示考慮到每個類別的樣本數量後，模型的整體性表現還不錯。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel(rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 1.49%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.00      0.00      0.00        19\n",
      "           2       0.00      0.00      0.00        19\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00        17\n",
      "           5       0.00      0.00      0.00        12\n",
      "           6       0.00      0.00      0.00        21\n",
      "           7       0.00      0.00      0.00        15\n",
      "           8       0.00      0.00      0.00        18\n",
      "           9       0.00      0.00      0.00        18\n",
      "          10       0.00      0.00      0.00        12\n",
      "          11       0.00      0.00      0.00        17\n",
      "          12       0.00      0.00      0.00        18\n",
      "          13       0.00      0.00      0.00        12\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00        13\n",
      "          16       0.00      0.00      0.00        18\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.00      0.00      0.00        17\n",
      "          19       0.01      1.00      0.03         9\n",
      "          20       0.00      0.00      0.00        10\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00        13\n",
      "          23       0.00      0.00      0.00        19\n",
      "          24       0.00      0.00      0.00        12\n",
      "          25       0.00      0.00      0.00        13\n",
      "          26       0.00      0.00      0.00        15\n",
      "          27       0.00      0.00      0.00        19\n",
      "          28       0.00      0.00      0.00        19\n",
      "          29       0.00      0.00      0.00        19\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        23\n",
      "          32       0.00      0.00      0.00        11\n",
      "          33       0.00      0.00      0.00        15\n",
      "          34       0.00      0.00      0.00        20\n",
      "          35       0.00      0.00      0.00        14\n",
      "          36       0.00      0.00      0.00        15\n",
      "          37       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.01       603\n",
      "   macro avg       0.00      0.03      0.00       603\n",
      "weighted avg       0.00      0.01      0.00       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVC(kernel=\"rbf\", gamma=0.2, **opts)\n",
    "train_and_evaluate(clf_svm, X_train_, X_test_, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果說明 :\n",
    "1. 測試資料之準確率1%。\n",
    "2. 在加權平均的評估指標中，精確率、召回率和F1分數分別為0.00、0.01、0.00，這表示考慮到每個類別的樣本數量後，模型的整體性表現很糟。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel(poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 60.36%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.75        17\n",
      "           1       1.00      0.68      0.81        19\n",
      "           2       1.00      0.32      0.48        19\n",
      "           3       0.09      0.93      0.17        14\n",
      "           4       1.00      0.76      0.87        17\n",
      "           5       0.78      0.58      0.67        12\n",
      "           6       0.50      0.05      0.09        21\n",
      "           7       0.50      0.53      0.52        15\n",
      "           8       1.00      0.56      0.71        18\n",
      "           9       1.00      0.56      0.71        18\n",
      "          10       1.00      0.58      0.74        12\n",
      "          11       1.00      0.41      0.58        17\n",
      "          12       1.00      0.50      0.67        18\n",
      "          13       0.89      0.67      0.76        12\n",
      "          14       1.00      0.82      0.90        17\n",
      "          15       1.00      0.69      0.82        13\n",
      "          16       0.92      0.61      0.73        18\n",
      "          17       0.85      0.73      0.79        15\n",
      "          18       0.64      0.53      0.58        17\n",
      "          19       1.00      0.89      0.94         9\n",
      "          20       0.90      0.90      0.90        10\n",
      "          21       1.00      0.56      0.72        16\n",
      "          22       0.92      0.92      0.92        13\n",
      "          23       1.00      0.42      0.59        19\n",
      "          24       1.00      0.67      0.80        12\n",
      "          25       1.00      0.54      0.70        13\n",
      "          26       1.00      0.87      0.93        15\n",
      "          27       0.86      0.63      0.73        19\n",
      "          28       0.71      0.26      0.38        19\n",
      "          29       1.00      0.47      0.64        19\n",
      "          30       0.33      0.83      0.48        12\n",
      "          31       0.89      0.35      0.50        23\n",
      "          32       1.00      0.91      0.95        11\n",
      "          33       0.26      0.73      0.39        15\n",
      "          34       1.00      0.65      0.79        20\n",
      "          35       0.78      0.50      0.61        14\n",
      "          36       0.33      0.93      0.48        15\n",
      "          37       0.93      0.65      0.76        20\n",
      "\n",
      "    accuracy                           0.60       603\n",
      "   macro avg       0.84      0.63      0.67       603\n",
      "weighted avg       0.84      0.60      0.66       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVC(kernel=\"poly\", degree=3, gamma=\"auto\", **opts)\n",
    "train_and_evaluate(clf_svm, X_train_, X_test_, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果說明 :\n",
    "1. 測試資料之準確率60%。\n",
    "2. 在加權平均的評估指標中，精確率、召回率和F1分數分別為0.84、0.60、0.66，這表示考慮到每個類別的樣本數量後，模型的整體性表現仍需加強。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類器性能：\n",
    "\n",
    "kernel(linear)表現最好，測試資料之準確率大約為93%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (四)神經網路（Neural Network）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1)以標準化後之原始資料的訓練資料學習，並以測試資料測試準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wesley\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76        17\n",
      "           1       0.89      0.94      0.92        18\n",
      "           2       0.67      0.74      0.70        19\n",
      "           3       0.73      0.89      0.80        18\n",
      "           4       1.00      0.88      0.93        16\n",
      "           5       0.83      0.79      0.81        19\n",
      "           6       0.84      0.80      0.82        20\n",
      "           7       0.78      0.88      0.82        24\n",
      "           8       1.00      0.83      0.91        18\n",
      "           9       1.00      0.71      0.83        17\n",
      "          10       0.90      0.69      0.78        13\n",
      "          11       0.91      0.67      0.77        15\n",
      "          12       0.80      0.80      0.80        15\n",
      "          13       0.82      0.82      0.82        11\n",
      "          14       0.78      0.93      0.85        15\n",
      "          15       0.71      1.00      0.83        12\n",
      "          16       0.94      0.94      0.94        16\n",
      "          17       0.94      1.00      0.97        16\n",
      "          18       0.59      0.91      0.71        11\n",
      "          19       0.84      0.84      0.84        19\n",
      "          20       0.92      1.00      0.96        12\n",
      "          21       0.91      0.95      0.93        22\n",
      "          22       0.89      0.80      0.84        10\n",
      "          23       0.67      0.83      0.74        12\n",
      "          24       0.85      0.73      0.79        15\n",
      "          25       0.87      0.87      0.87        15\n",
      "          26       0.83      1.00      0.91        10\n",
      "          27       0.67      0.62      0.65        16\n",
      "          28       0.84      0.89      0.86        18\n",
      "          29       0.82      0.82      0.82        17\n",
      "          30       0.76      0.87      0.81        15\n",
      "          31       1.00      0.67      0.80        15\n",
      "          32       0.62      0.91      0.74        11\n",
      "          33       0.90      0.86      0.88        21\n",
      "          34       0.93      0.87      0.90        15\n",
      "          35       0.92      0.92      0.92        13\n",
      "          36       0.94      0.89      0.91        18\n",
      "          37       1.00      0.79      0.88        19\n",
      "\n",
      "    accuracy                           0.84       603\n",
      "   macro avg       0.85      0.84      0.84       603\n",
      "weighted avg       0.85      0.84      0.84       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "activation = \"logistic\"\n",
    "opts = dict( verbose = False, \\\n",
    "activation = activation, tol = 1e-6, max_iter = int(1e8))\n",
    "solver = \"lbfgs\" # not suitable here\n",
    "clf_MLP = MLPClassifier(solver = solver, **opts)\n",
    "clf_MLP.fit(X_train, y_train)\n",
    "predictions = clf_MLP.predict(X_test)\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.00      0.00      0.00        14\n",
      "           2       0.00      0.00      0.00        19\n",
      "           3       0.00      0.00      0.00        21\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00        17\n",
      "           6       0.00      0.00      0.00        18\n",
      "           7       0.00      0.00      0.00        15\n",
      "           8       0.00      0.00      0.00        13\n",
      "           9       0.00      0.00      0.00        16\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.00      0.00      0.00        16\n",
      "          12       0.00      0.00      0.00        21\n",
      "          13       0.00      0.00      0.00        11\n",
      "          14       0.00      0.00      0.00        15\n",
      "          15       0.00      0.00      0.00        15\n",
      "          16       0.00      0.00      0.00        16\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.00      0.00      0.00        15\n",
      "          19       0.00      0.00      0.00        19\n",
      "          20       0.00      0.00      0.00        21\n",
      "          21       0.00      0.00      0.00        13\n",
      "          22       0.00      0.00      0.00        11\n",
      "          23       0.00      0.00      0.00        10\n",
      "          24       0.00      0.00      0.00        17\n",
      "          25       0.00      0.00      0.00        17\n",
      "          26       0.00      0.00      0.00        17\n",
      "          27       0.00      0.00      0.00        15\n",
      "          28       0.00      0.00      0.00        18\n",
      "          29       0.00      0.00      0.00        19\n",
      "          30       0.06      0.25      0.10        20\n",
      "          31       0.00      0.00      0.00        14\n",
      "          32       0.00      0.00      0.00        18\n",
      "          33       0.00      0.00      0.00        16\n",
      "          34       0.00      0.00      0.00        16\n",
      "          35       0.00      0.00      0.00        16\n",
      "          36       0.02      0.67      0.03        12\n",
      "          37       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.02       603\n",
      "   macro avg       0.00      0.02      0.00       603\n",
      "weighted avg       0.00      0.02      0.00       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用函數訓練模型\n",
    "train_MLP(\"adam\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.00      0.00      0.00        19\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         9\n",
      "           4       0.00      0.00      0.00        16\n",
      "           5       0.00      0.00      0.00        12\n",
      "           6       0.00      0.00      0.00        14\n",
      "           7       0.00      0.00      0.00        13\n",
      "           8       0.00      0.00      0.00        15\n",
      "           9       0.00      0.00      0.00        13\n",
      "          10       0.00      0.00      0.00        19\n",
      "          11       0.00      0.00      0.00        18\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.00      0.00      0.00        22\n",
      "          14       0.00      0.00      0.00        15\n",
      "          15       0.00      0.00      0.00        14\n",
      "          16       0.00      0.00      0.00        13\n",
      "          17       0.00      0.00      0.00        19\n",
      "          18       0.00      0.00      0.00        23\n",
      "          19       0.00      0.00      0.00        19\n",
      "          20       0.00      0.00      0.00        14\n",
      "          21       0.00      0.00      0.00        24\n",
      "          22       0.00      0.00      0.00        17\n",
      "          23       0.00      0.00      0.00        21\n",
      "          24       0.00      0.00      0.00        15\n",
      "          25       0.00      0.00      0.00        14\n",
      "          26       0.00      0.00      0.00        18\n",
      "          27       0.00      0.00      0.00        14\n",
      "          28       0.00      0.00      0.00        21\n",
      "          29       0.01      1.00      0.03         8\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        12\n",
      "          32       0.00      0.00      0.00        19\n",
      "          33       0.00      0.00      0.00        14\n",
      "          34       0.00      0.00      0.00        16\n",
      "          35       0.00      0.00      0.00        20\n",
      "          36       0.00      0.00      0.00        14\n",
      "          37       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.01       603\n",
      "   macro avg       0.00      0.03      0.00       603\n",
      "weighted avg       0.00      0.01      0.00       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_MLP(\"sgd\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類器性能：\n",
    "\n",
    "演算法(lbfgs)表現最好，測試資料之準確率大約為84%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)以標準化後之原始資料的主成分之訓練資料學習，並以測試資料測試準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train_MLP_with_PCA(solver, X_train, y_train, X_test, y_test):\n",
    "    # Define the PCA transformer\n",
    "    pca = PCA(n_components=45)\n",
    "\n",
    "    # Apply PCA to the training data and transform it\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    hidden_layers = (600,)\n",
    "    activation = \"logistic\"\n",
    "    opts = dict(hidden_layer_sizes = hidden_layers , verbose = False, \\\n",
    "    activation = activation, tol = 1e-6, max_iter = int(1e6))\n",
    "\n",
    "    clf_MLP = MLPClassifier(solver = solver, **opts)\n",
    "    clf_MLP.fit(X_train_pca, y_train)\n",
    "    predictions = clf_MLP.predict(X_test_pca)\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81        15\n",
      "           1       1.00      0.86      0.92        14\n",
      "           2       0.86      1.00      0.93        19\n",
      "           3       0.95      0.90      0.93        21\n",
      "           4       0.95      1.00      0.97        18\n",
      "           5       0.84      0.94      0.89        17\n",
      "           6       1.00      0.89      0.94        18\n",
      "           7       0.93      0.87      0.90        15\n",
      "           8       1.00      0.92      0.96        13\n",
      "           9       1.00      0.81      0.90        16\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      0.88      0.93        16\n",
      "          12       1.00      0.90      0.95        21\n",
      "          13       0.85      1.00      0.92        11\n",
      "          14       0.61      0.93      0.74        15\n",
      "          15       0.87      0.87      0.87        15\n",
      "          16       1.00      0.94      0.97        16\n",
      "          17       1.00      1.00      1.00        15\n",
      "          18       0.80      0.80      0.80        15\n",
      "          19       0.94      0.84      0.89        19\n",
      "          20       0.95      0.86      0.90        21\n",
      "          21       0.86      0.92      0.89        13\n",
      "          22       0.85      1.00      0.92        11\n",
      "          23       1.00      0.90      0.95        10\n",
      "          24       1.00      0.94      0.97        17\n",
      "          25       1.00      0.76      0.87        17\n",
      "          26       0.80      0.94      0.86        17\n",
      "          27       1.00      0.73      0.85        15\n",
      "          28       0.94      0.83      0.88        18\n",
      "          29       1.00      0.95      0.97        19\n",
      "          30       1.00      0.95      0.97        20\n",
      "          31       0.88      1.00      0.93        14\n",
      "          32       0.82      1.00      0.90        18\n",
      "          33       0.94      0.94      0.94        16\n",
      "          34       0.93      0.88      0.90        16\n",
      "          35       0.71      0.75      0.73        16\n",
      "          36       0.75      1.00      0.86        12\n",
      "          37       0.93      0.88      0.90        16\n",
      "\n",
      "    accuracy                           0.90       603\n",
      "   macro avg       0.91      0.91      0.91       603\n",
      "weighted avg       0.92      0.90      0.91       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用函數訓練模型\n",
    "train_MLP_with_PCA(\"adam\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果說明 :\n",
    "1. 測試資料之準確率90%。\n",
    "2. 在加權平均的評估指標中，精確率、召回率和F1分數分別為0.92、0.90、0.91，這表示考慮到每個類別的樣本數量後，模型的整體性表現還不錯。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.53      0.44        15\n",
      "           1       0.52      0.93      0.67        14\n",
      "           2       0.61      0.74      0.67        19\n",
      "           3       0.59      0.48      0.53        21\n",
      "           4       0.88      0.78      0.82        18\n",
      "           5       0.65      0.65      0.65        17\n",
      "           6       0.75      0.50      0.60        18\n",
      "           7       0.59      0.67      0.62        15\n",
      "           8       0.60      0.92      0.73        13\n",
      "           9       0.67      0.62      0.65        16\n",
      "          10       0.73      1.00      0.84         8\n",
      "          11       0.83      0.62      0.71        16\n",
      "          12       1.00      0.62      0.76        21\n",
      "          13       0.54      0.64      0.58        11\n",
      "          14       0.75      0.60      0.67        15\n",
      "          15       0.58      0.47      0.52        15\n",
      "          16       0.83      0.62      0.71        16\n",
      "          17       0.69      0.60      0.64        15\n",
      "          18       0.67      0.53      0.59        15\n",
      "          19       1.00      0.79      0.88        19\n",
      "          20       1.00      0.52      0.69        21\n",
      "          21       0.67      0.46      0.55        13\n",
      "          22       0.62      0.73      0.67        11\n",
      "          23       1.00      0.60      0.75        10\n",
      "          24       0.82      0.53      0.64        17\n",
      "          25       0.73      0.47      0.57        17\n",
      "          26       0.64      0.82      0.72        17\n",
      "          27       0.53      0.53      0.53        15\n",
      "          28       0.89      0.44      0.59        18\n",
      "          29       0.80      0.42      0.55        19\n",
      "          30       0.62      0.75      0.68        20\n",
      "          31       0.50      0.79      0.61        14\n",
      "          32       1.00      0.56      0.71        18\n",
      "          33       0.25      0.69      0.37        16\n",
      "          34       0.53      0.56      0.55        16\n",
      "          35       1.00      0.56      0.72        16\n",
      "          36       0.42      0.83      0.56        12\n",
      "          37       0.39      0.69      0.50        16\n",
      "\n",
      "    accuracy                           0.63       603\n",
      "   macro avg       0.69      0.64      0.64       603\n",
      "weighted avg       0.70      0.63      0.64       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用函數訓練模型\n",
    "train_MLP_with_PCA(\"sgd\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果說明 :\n",
    "1. 測試資料之準確率63%。\n",
    "2. 在加權平均的評估指標中，精確率、召回率和F1分數分別為0.70、0.63、0.64，這表示考慮到每個類別的樣本數量後，模型的整體性表現仍需加強。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.87      0.68        15\n",
      "           1       0.74      1.00      0.85        14\n",
      "           2       0.94      0.89      0.92        19\n",
      "           3       0.89      0.76      0.82        21\n",
      "           4       0.80      0.89      0.84        18\n",
      "           5       0.79      0.65      0.71        17\n",
      "           6       0.85      0.61      0.71        18\n",
      "           7       0.75      0.80      0.77        15\n",
      "           8       0.86      0.92      0.89        13\n",
      "           9       0.80      0.75      0.77        16\n",
      "          10       0.62      1.00      0.76         8\n",
      "          11       0.92      0.75      0.83        16\n",
      "          12       0.93      0.67      0.78        21\n",
      "          13       0.92      1.00      0.96        11\n",
      "          14       0.92      0.80      0.86        15\n",
      "          15       0.73      0.73      0.73        15\n",
      "          16       0.80      0.75      0.77        16\n",
      "          17       1.00      0.87      0.93        15\n",
      "          18       0.64      0.60      0.62        15\n",
      "          19       0.83      0.79      0.81        19\n",
      "          20       0.75      0.71      0.73        21\n",
      "          21       0.73      0.85      0.79        13\n",
      "          22       0.62      0.91      0.74        11\n",
      "          23       0.78      0.70      0.74        10\n",
      "          24       0.69      0.65      0.67        17\n",
      "          25       0.88      0.88      0.88        17\n",
      "          26       0.94      0.94      0.94        17\n",
      "          27       0.71      0.80      0.75        15\n",
      "          28       0.79      0.61      0.69        18\n",
      "          29       0.65      0.79      0.71        19\n",
      "          30       0.89      0.85      0.87        20\n",
      "          31       1.00      0.93      0.96        14\n",
      "          32       1.00      0.78      0.88        18\n",
      "          33       0.76      0.81      0.79        16\n",
      "          34       0.82      0.56      0.67        16\n",
      "          35       0.64      0.88      0.74        16\n",
      "          36       0.73      0.92      0.81        12\n",
      "          37       0.59      0.62      0.61        16\n",
      "\n",
      "    accuracy                           0.79       603\n",
      "   macro avg       0.80      0.80      0.79       603\n",
      "weighted avg       0.80      0.79      0.79       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用函數訓練模型\n",
    "train_MLP_with_PCA(\"lbfgs\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果說明 :\n",
    "1. 測試資料之準確率79%。\n",
    "2. 在加權平均的評估指標中，精確率、召回率和F1分數分別為0.80、0.79、0.79，這表示考慮到每個類別的樣本數量後，模型的整體性表現仍需加強。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類器性能：\n",
    "\n",
    "演算法(adam)表現最好，測試資料之準確率大約為90%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>對兩種資料型態與三個分類器的表現做比較</font>\n",
    "\n",
    "多元羅吉斯回歸 (Multinomial Logistic Regression)\n",
    "\n",
    "1. 原始資料 : accuracy大約97%\n",
    "2. 主成分資料(取前45個) : accuracy大約92%\n",
    "\n",
    "支援向量機 (Support Vector Machine)\n",
    "\n",
    "1. 原始資料 : accuracy大約91%\n",
    "2. 主成分資料(取前45個) : accuracy大約93%\n",
    "\n",
    "神經網路 (Neural Network)\n",
    "\n",
    "1. 原始資料 : accuracy大約84%\n",
    "2. 主成分資料(取前45個) : accuracy大約90%\n",
    "\n",
    "結果: \n",
    "1. 在原始資料下，多元羅吉斯回歸的測試資料之準確率最高，達97；再來是支援向量機，測試資料之準確率達91%；最後神經網路的測試資料之準確率也有84%，表現也不錯。\n",
    "2. 主成分資料(取前45個)下，支援向量機的測試資料之準確率最高，達93%；再來是多元羅吉斯回歸，測試資料之準確率達92%；最後神經網路的測試資料之準確率也有90%，表現也不錯。\n",
    "\n",
    "<font color=darkgoldenrod>個人見解</font> :\n",
    "\n",
    "1. 多元羅吉斯回歸和支援向量機在原始資料和主成分資料上的表現都優於神經網路，可能因為這兩種模型能更好地處理這組資料的複雜度和分佈。\n",
    "\n",
    "2. 神經網路在降維後的主成分資料上的表現下降，可能是由於資訊損失或模型複雜度過高。\n",
    "\n",
    "3. 雖然Yale Face資料集相對於其他兩個資料集大了許多，但還是不夠大，神經網路可能無法充分學習，而多元羅吉斯回歸和支援向量機作為較簡單的模型，則能在小型資料集上表現較好。\n",
    "\n",
    "4. 資料量對機器學習花的時間影響很大，葡萄酒的資料集的每個程式一分鐘內就可以跑完，而Yale Face資料集的每個程式都要多花很多時間，甚至有些程式跑了好幾個小時都跑不完，因此這個資料集我沒有用網格搜索（GridSearchCV）來尋找最佳的參數組合，而是改成手動調整參數，盡量產生最佳解。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
